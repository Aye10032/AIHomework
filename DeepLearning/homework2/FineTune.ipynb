{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-20T07:23:28.759247Z",
     "start_time": "2024-05-20T07:23:09.697612Z"
    }
   },
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset('cifar10')\n",
    "ds"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T07:23:33.420777Z",
     "start_time": "2024-05-20T07:23:33.333679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ex = ds['train'][400]\n",
    "ex"
   ],
   "id": "e8ec8529ab7b1fe7",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T07:23:43.785609Z",
     "start_time": "2024-05-20T07:23:43.780587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image = ex['img']\n",
    "image"
   ],
   "id": "6b5fac08d8901929",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T07:23:45.645764Z",
     "start_time": "2024-05-20T07:23:45.641688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "labels = ds['train'].features['label']\n",
    "labels"
   ],
   "id": "aadef7b7e11f1ba",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T04:26:01.822036Z",
     "start_time": "2024-05-20T04:26:01.818256Z"
    }
   },
   "cell_type": "code",
   "source": "labels.int2str(ex['label'])",
   "id": "7c7898b636a50b2e",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T07:23:49.817474Z",
     "start_time": "2024-05-20T07:23:49.581487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "from PIL import ImageDraw, Image\n",
    "\n",
    "def show_examples(_ds, seed: int = 1234, examples_per_class: int = 3, size=(200, 200)):\n",
    "\n",
    "    w, h = size\n",
    "    label = _ds['train'].features['label'].names\n",
    "    grid = Image.new('RGB', size=(examples_per_class * w, len(label) * h))\n",
    "    draw = ImageDraw.Draw(grid)\n",
    "    # font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationMono-Bold.ttf\", 24)\n",
    "\n",
    "    for label_id, label in enumerate(label):\n",
    "\n",
    "        # Filter the dataset by a single label, shuffle it, and grab a few samples\n",
    "        ds_slice = _ds['train'].filter(lambda ex: ex['label'] == label_id).shuffle(seed).select(range(examples_per_class))\n",
    "\n",
    "        # Plot this label's examples along a row\n",
    "        for i, example in enumerate(ds_slice):\n",
    "            _image = example['img']\n",
    "            idx = examples_per_class * label_id + i\n",
    "            box = (idx % examples_per_class * w, idx // examples_per_class * h)\n",
    "            grid.paste(_image.resize(size), box=box)\n",
    "            draw.text(box, label, (255, 255, 255))\n",
    "\n",
    "    return grid\n",
    "\n",
    "show_examples(ds, seed=random.randint(0, 1337), examples_per_class=3)"
   ],
   "id": "d44f1bcc414bca5d",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# load vit image processor",
   "id": "3c422f2d511e5351"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T07:24:21.755692Z",
     "start_time": "2024-05-20T07:23:54.220228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import ViTImageProcessor\n",
    "\n",
    "model_name_or_path = 'google/vit-base-patch16-224-in21k'\n",
    "processor = ViTImageProcessor.from_pretrained(model_name_or_path)\n",
    "processor"
   ],
   "id": "59befca6e19892f1",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T07:25:33.191979Z",
     "start_time": "2024-05-20T07:25:33.183991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img_pt = processor(image, return_tensors='pt')\n",
    "img_pt['pixel_values'].shape"
   ],
   "id": "5d080b8a7b83842d",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T07:25:34.986380Z",
     "start_time": "2024-05-20T07:25:34.983279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_example(example):\n",
    "    inputs = processor(example['img'], return_tensors='pt')\n",
    "    inputs['label'] = example['label']\n",
    "    return inputs"
   ],
   "id": "f45256c4f1e14341",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T07:25:37.060557Z",
     "start_time": "2024-05-20T07:25:37.051831Z"
    }
   },
   "cell_type": "code",
   "source": "process_example(ds['train'][0])",
   "id": "6b035d5555a25ed0",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T07:25:39.480836Z",
     "start_time": "2024-05-20T07:25:39.474958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def transform(example_batch):\n",
    "    # Take a list of PIL images and turn them to pixel values\n",
    "    inputs = processor([x for x in example_batch['img']], return_tensors='pt')\n",
    "\n",
    "    # Don't forget to include the labels!\n",
    "    inputs['labels'] = example_batch['label']\n",
    "    return inputs\n",
    "\n",
    "prepared_ds = ds.with_transform(transform)"
   ],
   "id": "56c879fe50f80cfe",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T07:29:34.840371Z",
     "start_time": "2024-05-20T07:29:34.836403Z"
    }
   },
   "cell_type": "code",
   "source": "prepared_ds",
   "id": "79f8378dd39853f1",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T07:25:44.288548Z",
     "start_time": "2024-05-20T07:25:44.285239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
    "        'labels': torch.tensor([x['labels'] for x in batch])\n",
    "    }"
   ],
   "id": "ec9cb03978605c26",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T07:26:04.991580Z",
     "start_time": "2024-05-20T07:25:59.182404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(p):\n",
    "    return metric.compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids)"
   ],
   "id": "d171b3c07b165203",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T07:27:01.135455Z",
     "start_time": "2024-05-20T07:26:46.324997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import ViTForImageClassification\n",
    "\n",
    "labels = ds['train'].features['label'].names\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    num_labels=len(labels),\n",
    "    id2label={str(i): c for i, c in enumerate(labels)},\n",
    "    label2id={c: str(i) for i, c in enumerate(labels)}\n",
    ")\n",
    "model"
   ],
   "id": "705c167aaaae5632",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T07:29:06.049161Z",
     "start_time": "2024-05-20T07:29:05.950104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=\"./vit-base-beans\",\n",
    "  per_device_train_batch_size=16,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=3,\n",
    "  fp16=True,\n",
    "  save_steps=100,\n",
    "  eval_steps=100,\n",
    "  logging_steps=10,\n",
    "  learning_rate=2e-4,\n",
    "  save_total_limit=2,\n",
    "  remove_unused_columns=False,\n",
    "  push_to_hub=False,\n",
    "  report_to='tensorboard',\n",
    "  load_best_model_at_end=True,\n",
    ")"
   ],
   "id": "642fccc78c062c56",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T07:29:47.026897Z",
     "start_time": "2024-05-20T07:29:46.684041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=prepared_ds[\"train\"],\n",
    "    eval_dataset=prepared_ds[\"test\"],\n",
    "    tokenizer=processor,\n",
    ")"
   ],
   "id": "fec39d9ef2cd3ca9",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T07:43:23.037995Z",
     "start_time": "2024-05-20T07:30:03.029923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_results = trainer.train()\n",
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_state()"
   ],
   "id": "53edca393ee4615e",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T07:44:03.078593Z",
     "start_time": "2024-05-20T07:43:44.937965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics = trainer.evaluate(prepared_ds['test'])\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ],
   "id": "9eaf22ad4067eca3",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T07:51:30.597347Z",
     "start_time": "2024-05-20T07:50:38.221567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "outputs = trainer.predict(prepared_ds['test'])\n",
    "y_true = outputs.label_ids\n",
    "y_pred = outputs.predictions.argmax(1)\n",
    "\n",
    "_labels = prepared_ds['test'].features['label'].names\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=_labels)\n",
    "disp.plot(xticks_rotation=45)\n",
    "plt.plot(disp)"
   ],
   "id": "625f15de8d75c6f",
   "execution_count": 23,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
